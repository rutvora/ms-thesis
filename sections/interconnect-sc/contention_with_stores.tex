\section{Creating contention with load/store instructions}
\label{sec:contention-with-stores}

We have outlined the types of transactions PCIe supports in \Cref{tab:pcie-transaction-types}.
Most PCIe transactions are non-posted and, hence, are synchronous.
The synchronous behaviour enforces that no two load/store (i.e. read or write) operations to the same PCIe region can be issued in parallel.
However, having multiple parallel transactions that are in flight at the same time is necessary for the attacker to always have one pending packet in the PCIe buffer targeted for the side-channel attack
\footnote{An attacker can measure the delay in the transmission of that packet and infer the presence or absence of the victim traffic}.
As such, the attacker can only rely on non-posted transactions, and in particular, memory write operations
\footnote{While messages are also non-posted, they are usually generated by the underlying hardware directly, and the user has no control over those messages}.

In order to generate memory writes from the CPU, the attacker can map the device memory of a PCIe device, like a GPU, to an application running on the CPU and then issue store operations on that mapped memory.
Multiple store operations can be asynchronously issued on most modern processors as they support out-of-order execution. 
However, the same out-of-order execution feature makes it difficult for the attacker to accurately measure a store operation's time since the timer instruction can also be executed out of order.
In order to measure time accurately, most applications rely on issuing a fence instruction
\footnote{A fence instruction imposes ordering constraints, thus ensuring that any instruction after the fence is not executed before \textit{all} instructions before the fence are executed}.
However, this solution would not work for the attacker as the fence would not allow the next store instruction to be issued in parallel to the previous one, negating the benefit of using a posted (async) transaction.


\subsection{Measuring time of async stores}
\label{subsec:async_store_time}

In order to measure the completion time of a store operation which is issued out-of-order, we make use of two key insights:

\textit{First}, the CPU core would need to keep track of all instructions executed out-of-order so that they are retired in program order.
Keeping this track would require a scheduler and a buffer in the hardware, which would have a limited and fixed size.
The AMD CPU has four schedulers as described in \Cref{subsubsec:cpu-pipelines-bg}. Each scheduler has a fixed number of instruction slots $size_{sched}$.
In addition, for tracking load and store operations that are in flight, the CPU also has an LSQ, with a fixed number of slots for loads ($size_{ldq}$) and for stores ($size_{stq}$).
So, if the total number of pending (in flight) store instructions is larger than the total size of the scheduler slots and the store queue, the next instruction will be blocked, until one (or more) of the previous instructions finishes.

\textit{Second}, it is sufficient for the attacker to know if \textit{a} store instruction was delayed, and not if a particular store instruction was delayed.
% Convince why this is the case.
This would mean that we can use the first insight to queue a timer instruction immediately after issuing $size_{sched} + size_{stq}$ stores, and that timer will execute only after a store has completed.


\subsection{Evaluation}
\label{subsec:store-eval}

\endinput
